{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires python>=3.10\n",
    "# %pip install pandas google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from google.cloud import storage\n",
    "# from pathlib import Path\n",
    "\n",
    "\n",
    "# bucket_name = \"ml2-public\"\n",
    "# prefix = \"prop-sat/sem-1/\"\n",
    "\n",
    "# storage_client = storage.Client.create_anonymous_client()\n",
    "# bucket = storage_client.get_bucket(bucket_or_name=bucket_name)\n",
    "# blobs = bucket.list_blobs(prefix=prefix)  # Get list of files\n",
    "# for blob in blobs:\n",
    "#     if blob.name.endswith(\"/\"):\n",
    "#         continue\n",
    "#     directory = os.path.join(\"storage\", *blob.name.split(\"/\")[1:-1])\n",
    "#     Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "#     blob.download_to_filename(os.path.join(\"storage\", *blob.name.split(\"/\")[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SATDataset, SplitDataset\n",
    "from vocabulary import Vocabulary\n",
    "from datatypes import SATAssignment, CNFFormula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load dataset from file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits: SplitDataset = SplitDataset.load(\"./storage/sem-1\")\n",
    "test: SATDataset = splits[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits.splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get first Sample form Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(test.generator())\n",
    "print(repr(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = test[0]\n",
    "print(repr(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the input (formula)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = sample.input\n",
    "print(repr(formula))\n",
    "print(formula.to_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the target (assignment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment = sample.target\n",
    "print(repr(assignment))\n",
    "print(assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize formula and assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert SATAssignment.from_tokens(assignment.to_tokens()) == assignment\n",
    "assignment.to_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert CNFFormula.from_tokens(formula.to_tokens()) == formula\n",
    "formula.to_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary(\"./storage/sem-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(assignment.to_tokens())\n",
    "print(vocab.to_vocab(assignment.to_tokens()))\n",
    "print(vocab.from_vocab(vocab.to_vocab(assignment.to_tokens())))\n",
    "vocab.from_vocab(vocab.to_vocab(assignment.to_tokens())) == assignment.to_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(formula.to_tokens())\n",
    "print(vocab.to_vocab(formula.to_tokens()))\n",
    "print(vocab.from_vocab(vocab.to_vocab(formula.to_tokens())))\n",
    "vocab.from_vocab(vocab.to_vocab(formula.to_tokens())) == formula.to_tokens()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsc_seminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
